import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import glob # íŒŒì¼ ëª©ë¡ì„ ì°¾ê¸° ìœ„í•´ ì‚¬ìš©

# ---------------------------------------------------------
# 1. ê¸°ë³¸ ì„¤ì • ë° í•œê¸€ í°íŠ¸
# ---------------------------------------------------------
st.set_page_config(page_title="ì—°ë„ë³„ í†µí•© íŠ¸ë Œë“œ ë¶„ì„", layout="wide")

try:
    plt.rcParams['font.family'] = 'Malgun Gothic'
except:
    plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

# ---------------------------------------------------------
# 2. ë°ì´í„° ë¡œë“œ (ì—¬ëŸ¬ CSV íŒŒì¼ í†µí•© ê¸°ëŠ¥ ì¶”ê°€)
# ---------------------------------------------------------
@st.cache_data
def load_all_data(file_list):
    all_dfs = []
    
    for file_path in file_list:
        try:
            df = pd.read_csv(file_path)
            
            # ê²°ì¸¡ì¹˜ ì œê±° (ë¹ˆ ì¤„ ì‚­ì œ)
            df = df.dropna(subset=['Date', 'Keyword', 'Count'])
            
            # ë‚ ì§œ ë³€í™˜ í•¨ìˆ˜ (ë‘ ê°€ì§€ í˜•ì‹ ëª¨ë‘ ì§€ì›)
            def parse_date(date_str):
                try:
                    # 1. '16-Mar' (ë…„-ì›”) í˜•ì‹
                    return pd.to_datetime(date_str, format='%y-%b')
                except:
                    try:
                        # 2. 'Sep-16' (ì›”-ë…„) í˜•ì‹
                        return pd.to_datetime(date_str, format='%b-%y')
                    except:
                        return pd.NaT

            df['Date_Parsed'] = df['Date'].apply(parse_date)
            df = df.dropna(subset=['Date_Parsed']) # ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨ í–‰ ì œê±°
            
            all_dfs.append(df)
            
        except Exception as e:
            st.error(f"'{file_path}' ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            
    if all_dfs:
        # ëª¨ë“  ì—°ë„ì˜ ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
        return pd.concat(all_dfs, ignore_index=True)
    else:
        return pd.DataFrame()

# ---------------------------------------------------------
# 3. í•™ìƒ ìƒê¸°ë¶€ ë§¤í•‘ ë°ì´í„° (í•„ìš” ì‹œ ìˆ˜ì •/ì¶”ê°€)
# ---------------------------------------------------------
STUDENT_RECORDS = {
    # 2016ë…„
    "ì•ŒíŒŒê³ ": "2016-09-15",
    "í¬ì¼“ëª¬GO": "2016-10-20", 
    "ê²½ì£¼ ì§€ì§„": "2016-11-01",
    "ê°€ìŠµê¸° ì‚´ê· ì œ": "2016-05-20",
    # 2017ë…„
    "4ì°¨ì‚°ì—…í˜ëª…": "2017-09-10",
    "ë¯¸ì„¸ë¨¼ì§€": "2017-05-15",
    "ë¹„íŠ¸ì½”ì¸": "2018-01-20", # ì‹œì°¨ê°€ í•´ë¥¼ ë„˜ê¸¸ ìˆ˜ë„ ìˆìŒ
    "í¬í•­ ì§€ì§„": "2017-11-20",
    # 2018ë…„
    "ë‚¨ë¶íšŒë‹´": "2018-05-01",
    "í‰ì°½ ì˜¬ë¦¼í”½": "2018-03-10",
    "BMW í™”ì¬": "2018-09-01"
}

# ---------------------------------------------------------
# 4. ë©”ì¸ ì•± ë¡œì§
# ---------------------------------------------------------
st.title("ğŸ“Š ì—°ë„ë³„ CSV í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ")

# (1) ë°ì´í„° ë¡œë“œ: íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ì§€ì •í•˜ê±°ë‚˜, globìœ¼ë¡œ ì°¾ì„ ìˆ˜ ìˆìŒ
target_files = ['data/keyword/2016ë…„ í‚¤ì›Œë“œ.csv', 'data/keyword/2017ë…„ í‚¤ì›Œë“œ.csv', 'data/keyword/2018ë…„ í‚¤ì›Œë“œ.csv', 'data/keyword/2021ë…„ í‚¤ì›Œë“œ.csv'
                ,'data/keyword/2022ë…„ í‚¤ì›Œë“œ.csv', 'data/keyword/2023ë…„ í‚¤ì›Œë“œ.csv', 'data/keyword/2024ë…„ í‚¤ì›Œë“œ.csv']
# ë§Œì•½ íŒŒì¼ì´ ë” ë§ë‹¤ë©´ ì•„ë˜ ì£¼ì„ì„ í’€ì–´ì„œ ìë™ìœ¼ë¡œ ì°¾ê²Œ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
# target_files = glob.glob("*ë…„ í‚¤ì›Œë“œ.csv") 

df = load_all_data(target_files)

if not df.empty:
    # (2) ì‚¬ì´ë“œë°”: ì¹´í…Œê³ ë¦¬ ì„ íƒ
    st.sidebar.header("ğŸ” ë¶„ì„ ì˜µì…˜")
    
    categories = df['Category'].unique()
    selected_category = st.sidebar.selectbox("ë¶„ì„í•  ì¹´í…Œê³ ë¦¬ ì„ íƒ", categories)
    
    # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ë°ì´í„°ë§Œ ì¶”ì¶œ
    category_df = df[df['Category'] == selected_category]
    keywords_in_category = category_df['Keyword'].unique()
    
    st.header(f"ğŸ“‚ [{selected_category}] ë¶„ì•¼ í‚¤ì›Œë“œë³„ ìƒì„¸ ë¶„ì„")
    st.caption(f"ì´ {len(keywords_in_category)}ê°œì˜ ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # (3) í‚¤ì›Œë“œë³„ë¡œ ê·¸ë˜í”„ ë”°ë¡œ ê·¸ë¦¬ê¸° (ë°˜ë³µë¬¸)
    for kw in keywords_in_category:
        st.markdown("---") # êµ¬ë¶„ì„ 
        
        # íŠ¹ì • í‚¤ì›Œë“œ ë°ì´í„° ì¶”ì¶œ ë° ì •ë ¬
        subset = category_df[category_df['Keyword'] == kw].sort_values('Date_Parsed')
        
        # ë°ì´í„°ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸
        if subset.empty:
            continue
            
        # ë ˆì´ì•„ì›ƒ: ì™¼ìª½(ê·¸ë˜í”„) / ì˜¤ë¥¸ìª½(ì„¤ëª…)
        col1, col2 = st.columns([3, 1])
        
        with col1:
            fig, ax1 = plt.subplots(figsize=(10, 4))
            
            # ë‰´ìŠ¤ íŠ¸ë Œë“œ ì„  ê·¸ë˜í”„
            ax1.plot(subset['Date_Parsed'], subset['Count'], 
                     marker='o', markersize=4, color='#1f77b4', label='ë‰´ìŠ¤ ë¹ˆë„')
            
            # ìƒê¸°ë¶€ ê¸°ë¡ ì‹œì  (ë¹¨ê°„ì„ ) í‘œì‹œ
            if kw in STUDENT_RECORDS:
                record_date = pd.to_datetime(STUDENT_RECORDS[kw])
                
                # ê·¸ë˜í”„ Xì¶• ë²”ìœ„ ìë™ ì¡°ì • (ìƒê¸°ë¶€ ë‚ ì§œê°€ ê·¸ë˜í”„ ë²”ìœ„ë¥¼ ë²—ì–´ë‚  ê²½ìš° ëŒ€ë¹„)
                min_date = min(subset['Date_Parsed'].min(), record_date)
                max_date = max(subset['Date_Parsed'].max(), record_date)
                # ì—¬ìœ  ê³µê°„ ì¶”ê°€ (7ì¼ ì •ë„)
                ax1.set_xlim(min_date - pd.Timedelta(days=15), max_date + pd.Timedelta(days=15))

                # ìˆ˜ì§ì„ 
                ax1.axvline(x=record_date, color='red', linestyle='--', linewidth=1.5, label='ìƒê¸°ë¶€ ê¸°ë¡')
                # ë³„ ë§ˆì»¤
                ax1.scatter([record_date], [subset['Count'].max() * 0.5], color='red', s=150, marker='*', zorder=5)
                # í…ìŠ¤íŠ¸
                ax1.text(record_date, subset['Count'].max() * 0.55, " ìƒê¸°ë¶€", color='red', fontweight='bold')

            # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ë§
            ax1.set_title(f"'{kw}' ë‰´ìŠ¤ íŠ¸ë Œë“œ", fontsize=14, fontweight='bold')
            ax1.set_ylabel('ê¸°ì‚¬ ê±´ìˆ˜')
            ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
            ax1.grid(True, linestyle='--', alpha=0.3)
            ax1.legend()
            
            st.pyplot(fig)
            
        with col2:
            # í†µê³„ ìš”ì•½ ì¹´ë“œ
            max_val = subset['Count'].max()
            peak_date = subset.loc[subset['Count'].idxmax(), 'Date_Parsed']
            dept_name = subset.iloc[0]['Department']
            
            st.subheader(f"ğŸ“Œ {kw}")
            st.write(f"**ê´€ë ¨ í•™ê³¼:** {dept_name}")
            st.write(f"**ìµœê³  í™”ì œ:** {peak_date.strftime('%Yë…„ %mì›”')}")
            st.write(f"**ìµœëŒ€ ê¸°ì‚¬:** {int(max_val)}ê±´")
            
            if kw in STUDENT_RECORDS:
                rec_date = pd.to_datetime(STUDENT_RECORDS[kw])
                diff_days = (rec_date - peak_date).days
                lag_months = round(diff_days / 30, 1)
                
                if diff_days > 0:
                    st.success(f"â±ï¸ **ì‹œì°¨: +{lag_months}ê°œì›”**\n(ë‰´ìŠ¤ í›„ ë°˜ì˜ë¨)")
                else:
                    st.warning(f"â±ï¸ **ì‹œì°¨: {lag_months}ê°œì›”**\n(ë™ì‹œ/ì‚¬ì „ ë°˜ì˜)")
            else:
                st.info("ìƒê¸°ë¶€ ë°ì´í„° ì—†ìŒ")

    # (4) í•˜ë‹¨ì— ì „ì²´ í†µí•© ë°ì´í„° í…Œì´ë¸” (ì ‘ê¸°)
    with st.expander("ğŸ’¾ í†µí•© ë°ì´í„° ì›ë³¸ ë³´ê¸°"):
        st.dataframe(category_df.sort_values(['Keyword', 'Date_Parsed']))

else:
    st.error("ë¶ˆëŸ¬ì˜¬ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. í´ë”ì— csv íŒŒì¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")